---
title: "Supporting assortment selection process for coffee shop"
author: "Alicja Komorniczak 260549, Adam Kawałko 262329"
date: "`r format(Sys.time(), '%m/%d/%Y %X')`"
output:
  rmdformats::readthedown:
    highlight: kate
    number_sections: true
    self_contained: true
---

```{r setup, include=FALSE}
## Global options
library(knitr)
opts_chunk$set(echo = TRUE, 
               cache = FALSE,
               prompt = FALSE,
               tidy = TRUE,
               comment = NA,
               message = FALSE,
               warning = FALSE,
               fig.width = 7.4,
               fig.height = 4.7,
               fig.align = "center")
opts_knit$set(width = 80)
```

# Introduction

This report focuses on the analysis of a large dataset of coffee products, which includes a variety of specifications, ratings, and other characteristics related to the products. Our goal is to gain insights into the coffee market, examining factors such as price range, ratings, and the relationship between coffee specifications and their adjusted ratings. Through data cleaning and statistical analysis, we aim to uncover trends and patterns in the dataset that can help understand trends and dependencies in coffee market.

The information we got from konesso website contains several attributes, such as price, rating, number of opinions, flavor profiles (bitterness, acidity, sweetness, flavor intensity), and other product specifications like the coffee's origin, roaster, and packaging. Using this information, we perform a series of transformations and visualizations to provide a deeper understanding of how different factors contribute to coffee ratings and market pricing.   

# Data scraping
(
In order to obtain dataset with information about bean coffees from konesso website (https://www.konesso.pl/pol_m_Kawa_Rodzaj_Kawa-ziarnista-2160.html) with all necessary attributes for analysis, we scrape this information using appropriate code in R.
From each coffee bean product on konesso we scraped the following information: 

1. Product name,
2. Product description,
3. Specifications (such as degree of smoking, acidity etc.),
4. Price,
5. Producer,
6. Rating,
7. Number of reviews.

These were the key attributes targeted for extraction during this project.

## Main core of scraper

All necessary libraries were imported at the beginning of the script to handle `HTTP` requests, parse `HTML` content, process text data, and handle potential errors during the scraping process.

```{r}
library(httr)
library(rvest)
library(stringi)
```
The base URL of the webpage was defined, and an `HTTP GET` request was sent to access the page content while using a user-agent header.
```{r}
# Fetch content of the webpage with a user-agent header
url <- "https://www.konesso.pl/pol_m_Kawa_Rodzaj_Kawa-ziarnista-2160.html"


# response <- tryCatch(
#   GET(url, user_agent("Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36")),
#   error = function(e) stop("Error during page fetch: ", e)
# )
```

Once the page's content was retrieved successfully, it was parsed into an `HTML` object using the `rvest` package, and product containers were extracted for further processing. 

```{r}
# Check status of the response (now we skip this as no data will be fetched)
# if (status_code(response) != 200) stop("Failed to fetch page content")
# webpage <- tryCatch(
#   content(response, "text", encoding = "UTF-8") %>% read_html(),
#   error = function(e) stop("Error during page parsing: ", e)
# )
```

## Data Extraction

The scraper iteratively processed each product container to extract specific attributes. For each attribute, list was initialized to store them. A delay of two seconds `(Sys.sleep(1))` was implemented between each iteration to avoid overwhelming the server and potential blocking.

For the purpose of example, the code below contains sample data instead of scraped content. The full scraping code is available in the attachment file `scraper.R`.

```{r}

# Initialize lists to store data
# Using sample data instead of scraped content
product_containers <- list()  # No actual data to process
titles <- c("Sample Title 1", "Sample Title 2", "Sample Title 3", "Sample Title 4", "Sample Title 5")
descriptions <- c("Product description 1", "Product description 2", "Product description 3", "Product description 4", "Product description 5")
specifications_list <- list(
  c("Specification 1.1", "Specification 1.2"),
  c("Specification 2.1", "Specification 2.2"),
  c("Specification 3.1", "Specification 3.2"),
  c("Specification 4.1", "Specification 4.2"),
  c("Specification 5.1", "Specification 5.2")
)
prices <- c("39.99", "45.50", "50.00", "60.75", "55.00")
producers <- c("Producer 1", "Producer 2", "Producer 3", "Producer 4", "Producer 5")
ratings <- c(4.5, 4.7, 4.0, 4.3, 4.8)
reviews_counts <- c(100, 150, 200, 50, 120)

# Create a data frame from the first 5 products
num_products <- min(5, length(titles))
data <- data.frame(
  Title = titles[1:num_products],
  Description = descriptions[1:num_products],
  Price = prices[1:num_products]
)
data$Specifications <- specifications_list[1:num_products]

```

Scraped data was saved in dataframe and later extracted into `CSV` file: `kawa_with_bom_ok.CSV`.


# Data cleaning

At the beginning of data cleaning, the used libraries are loaded.
```{r}
# Load necessary libraries
library(tidyverse)
library(stringi)
library(dplyr)
library(ggplot2)
library(reshape2)
```

Previously saved dataframe with scraped data was imported into `df_kawa` dataframe in R with `UTF-8` encoding using `read_csv2`.

```{r}
df_kawa <- read_csv2("kawa_with_bom_ok.csv", locale = locale(encoding = "UTF-8"))
```

Next, a function `process_specifications` is defined to split and parse the specifications text into key-value pairs.
The function:

1. Splits the text by " | ".
2. Extracts keys (before :) and values (after :).
3. Returns a named list.

This function is applied to the Specifications column in the dataset. This is because while importing specifications such as bitterness, acidity etc. into a single dataframe columns, they were divided by " | ".


```{r}
# Define a function to process specifications from coffee data
process_specifications <- function(specifications_text) {
  specs <- stri_split_fixed(specifications_text, " | ", simplify = TRUE)
  spec_names <- stri_extract(specs, regex = "^[^:]+(?=:)")
  spec_values <- stri_extract(specs, regex = "(?<=:).+$")
  spec_list <- setNames(spec_values, spec_names)
  return(spec_list)
}
```

Processed specifications are used for creating new columns and original `Specifications` column is removed from dataframe. Then the columns where there is more than 1000 empty values are removed due to being unnecessary for further analysis. Last step in segment below is used for changing column names.


```{r}
specifications_processed <- lapply(df_kawa$Specifications, process_specifications)
specifications_df <- bind_rows(specifications_processed)
df_kawa <- bind_cols(df_kawa, specifications_df)
df_kawa <- df_kawa %>% select(-Specifications)

# Identify the number of non-NA values in each column
non_na_counts <- colSums(!is.na(df_kawa))

# Filter columns where the number of non-NA values is greater than or equal to 1000
df_kawa_filtered <- df_kawa[, non_na_counts >= 1000]

# Rename columns, with underscores instead of spaces and hyphens
colnames(df_kawa_filtered) <- c(
  "Tytuł", "Opis", "Cena", "Producent", "Ocena", "Liczba_opinii",
  "Skład", "Stopień_palenia", "Zawartość_kofeiny", "Rodzaj", "Palarnia", 
  "Przeznaczenie", "Opakowanie", "Sposób_przygotowania", "Crema", "Wyczuwalne_smaki", 
  "Intensywność_smaku", "Gorycz", "Kwasowość", "Słodycz", 
  "Pochodzenie_ziaren", "Blend_czy_Single", "Polecana_do", "Kawa_Specialty"
)

# Replace spaces and hyphens with underscores in column names
colnames(df_kawa_filtered) <- gsub(" |-", "_", colnames(df_kawa_filtered))
```

The trouble we came across while initially analysing data from the website, mainly specifications, is that there are various scales used for describing coffee flavors and characteristics. In some cases, there were levels explained by words (like "weak", "medium", "strong") and sometimes the 1-5 scale was used. 
A function `convert_to_5_scale` standardizes subjective or numeric ratings (like "2/5" or "Medium") into a scale from 0.2 to 1:

1. "Delicate" → 0.2
2. "Medium" → 0.6
3. "Strong" → 1

Numerical fractions (e.g., "2/5") are converted to decimals.
This is applied to columns such as `Bitterness`, `Acidity`, `Sweetness`, and `Flavor_intensity`.

```{r}
# Function to convert values to a 1/5 to 5/5 scale
convert_to_5_scale <- function(value) {
  value <- gsub(" ", "", value)  # Remove white spaces
  if (grepl("Delicate", value)) {
    return(0.2)
  } else if (grepl("Medium", value)) {
    return(0.6)
  } else if (grepl("Strong", value)) {
    return(1)
  }
  
  # For numeric values like "2/5", "3/5"
  if (grepl("^\\d+/\\d+$", value)) {
    return(as.numeric(stri_extract(value, regex = "^\\d+")) / as.numeric(stri_extract(value, regex = "(?<=/).*")))
  }
  
  # For numeric values like "1", "2", "3", "4", "5"
  if (grepl("^\\d+$", value)) {
    if (as.numeric(value) == 1) {
      return(0.2)
    } else if (as.numeric(value) == 2) {
      return(0.4)
    } else if (as.numeric(value) == 3) {
      return(0.6)
    } else if (as.numeric(value) == 4) {
      return(0.8)
    } else {
      return(1)
    }
  }
  
  return(NA)
}
```
Several other changes were made that involved either transforming the existing data or creating new column:

1. Dividing the price by 100 and format it to two decimal places,
2. Calculating price per gram,
3. The products were divided into price ranges and were assigned appropriate label based on price per gram.

Cleaned and filtered data was then saved into `kawa_filtered.csv` file. Full file with data cleaning can be found in attached file `cleaner.R`.


# Analysis

The analysis focuses on leveraging data scraped from the konesso website to gain actionable insights for coffee assortment selection in a coffee shop. This involves examining relationships between key coffee attributes, pricing, and customer preferences to support decision-making. By using statistical and visual techniques, the analysis identifies patterns and trends that are critical for optimizing product offerings and meeting diverse customer needs.

```{r}
# Loading libraries
library(tidyverse)
library(ggplot2)

# Reading data from "kawa_filtered.csv"
df_kawa_filtered <- read.csv("kawa_filtered.csv")

# General statistics
summary_stats <- df_kawa_filtered %>%
  select(Cena, Ocena, Liczba_opinii, Gorycz, Kwasowość, Słodycz, Intensywność_smaku, Cena_za_gram, Skorygowana_ocena) %>%
  summary()

# Additional statistics: mean, standard deviation, min, max
detailed_stats <- df_kawa_filtered %>%
  select(Cena, Ocena, Liczba_opinii, Gorycz, Kwasowość, Słodycz, Intensywność_smaku, Cena_za_gram, Skorygowana_ocena) %>%
  summarise(
    Mean_Cena = mean(Cena, na.rm = TRUE),
    SD_Cena = sd(Cena, na.rm = TRUE),
    Min_Cena = min(Cena, na.rm = TRUE),
    Max_Cena = max(Cena, na.rm = TRUE),
    
    Mean_Ocena = mean(Ocena, na.rm = TRUE),
    SD_Ocena = sd(Ocena, na.rm = TRUE),
    Min_Ocena = min(Ocena, na.rm = TRUE),
    Max_Ocena = max(Ocena, na.rm = TRUE),
    
    Mean_Liczba_opinii = mean(Liczba_opinii, na.rm = TRUE),
    SD_Liczba_opinii = sd(Liczba_opinii, na.rm = TRUE),
    Min_Liczba_opinii = min(Liczba_opinii, na.rm = TRUE),
    Max_Liczba_opinii = max(Liczba_opinii, na.rm = TRUE),
    
    Mean_Gorycz = mean(Gorycz, na.rm = TRUE),
    SD_Gorycz = sd(Gorycz, na.rm = TRUE),
    Min_Gorycz = min(Gorycz, na.rm = TRUE),
    Max_Gorycz = max(Gorycz, na.rm = TRUE),
    
    Mean_Kwasowość = mean(Kwasowość, na.rm = TRUE),
    SD_Kwasowość = sd(Kwasowość, na.rm = TRUE),
    Min_Kwasowość = min(Kwasowość, na.rm = TRUE),
    Max_Kwasowość = max(Kwasowość, na.rm = TRUE),
    
    Mean_Słodycz = mean(Słodycz, na.rm = TRUE),
    SD_Słodycz = sd(Słodycz, na.rm = TRUE),
    Min_Słodycz = min(Słodycz, na.rm = TRUE),
    Max_Słodycz = max(Słodycz, na.rm = TRUE),
    
    Mean_Intensywność_smaku = mean(Intensywność_smaku, na.rm = TRUE),
    SD_Intensywność_smaku = sd(Intensywność_smaku, na.rm = TRUE),
    Min_Intensywność_smaku = min(Intensywność_smaku, na.rm = TRUE),
    Max_Intensywność_smaku = max(Intensywność_smaku, na.rm = TRUE),
    
    Mean_Cena_za_gram = mean(Cena_za_gram, na.rm = TRUE),
    SD_Cena_za_gram = sd(Cena_za_gram, na.rm = TRUE),
    Min_Cena_za_gram = min(Cena_za_gram, na.rm = TRUE),
    Max_Cena_za_gram = max(Cena_za_gram, na.rm = TRUE)
  )
```

This part (above) of the R code calculates general statistics (e.g., mean, standard deviation, minimum, maximum) for key variables such as price (Cena), rating (Ocena), and sensory attributes like bitterness (Gorycz), acidity (Kwasowość), and sweetness (Słodycz). Using the `summary` function and the `summarise` method, the code provides an overview of the dataset and detailed insights into each attribute.
These statistics help identify central tendencies and variations in coffee attributes, which helps in understanding the diversity of available products.

The code part showed below creates a histogram which illustrates the distribution of coffee prices per gram, with bins set at a width of 0.01. Analyzing price distribution reveals whether products cluster into budget, midrange, or premium categories, aiding in targeting diverse customer segments.

```{r}
# Plotting distribution of price per gram
ggplot(df_kawa_filtered, aes(x = Cena_za_gram)) +
  geom_histogram(binwidth = 0.01, fill = "skyblue", color = "black") +
  labs(title = "Distribution of Price per Gram", x = "Price per Gram in PLN", y = "Number of Coffees")
```

The histogram shows that most coffee prices fall between 0.1 - 0.2 PLN per gram, indicating a dominance of budget and mid-range products. A smaller premium segment exists, with prices exceeding 1 PLN per gram, but it is less common. The distribution suggests product clustering based on quality, branding, or processing methods. Overall, the market is primarily focused on affordable coffee, with fewer high-end options.

A scatter plot is created to visualize the relationship between coffee prices and their ratings. The x-axis represents price, while the y-axis represents the rating. Points are plotted with semi-transparency (`alpha=0.5`) to manage overlapping data.
This visualization explores whether premium pricing correlates with higher ratings, guiding pricing strategies for high-quality products.

```{r}

# Scatter plot of price vs rating
ggplot(df_kawa_filtered, aes(x = Cena, y = Ocena)) +
  geom_point(color = "blue", alpha = 0.5) +
  labs(title = "Price vs Rating", x = "Price per Kilograms in PLN", y = "Rating")
```

The scatter plot shows the relationship between coffee price and rating. Most ratings cluster around 4-5, regardless of price, suggesting that both budget and expensive coffees tend to receive high ratings. However, there are also many zero ratings, which could indicate missing data or products with no reviews. There is no clear upward trend, meaning higher prices do not necessarily correlate with better ratings.

A boxplot groups coffee products by predefined price ranges and compares their ratings. The box's height represents the interquartile range (IQR), showing the middle 50% of ratings for each price range. Outliers are marked separately.
Understanding the distribution of ratings across price tiers highlights which segments offer the best value for customers.

```{r}

# Boxplot by price range
ggplot(df_kawa_filtered, aes(x = Przedział_cenowy, y = Ocena)) +
  geom_boxplot(fill = "lightgreen") +
  labs(title = "Rating by Price Range", x = "Price Range", y = "Rating")
```

The Rating by Price Range chart shows that both budget and premium coffees receive similarly high ratings, while mid-range coffees exhibit greater variation. The median rating remains consistently high across all categories, suggesting that price does not strongly influence customer satisfaction.

The code aggregates data to identify the producers with the highest number of total reviews. The `ggplot2` library generates a horizontal bar chart, showing producers ordered by review count.
This plot identifies producers with strong market presence and customer trust, valuable for deciding partnerships or key product lines.

```{r}
# Identify Most Popular Producers
# Count reviews per producer
popular_producers <- df_kawa_filtered %>%
  group_by(Producent) %>%
  summarise(Total_Reviews = sum(Liczba_opinii, na.rm = TRUE)) %>%
  arrange(desc(Total_Reviews)) %>%
  head(5)

# Bar plot of most popular producers
ggplot(popular_producers, aes(x = reorder(Producent, Total_Reviews), y = Total_Reviews)) +
  geom_bar(stat = "identity", fill = "dodgerblue") +
  coord_flip() +
  labs(title = "Top 5 Most Popular Producers by Total Reviews", x = "Producer", y = "Total Reviews")
```

The Top 5 Most Popular Producers by Total Reviews chart highlights that LAVAZZA and DALLMAYR are the most reviewed brands, indicating strong customer engagement and market presence. Other producers have significantly fewer reviews, suggesting either a smaller customer base or lower brand recognition.

This section identifies the top producers offering the cheapest coffee products based on average price per gram. The data is grouped by producer and the mean price per gram is calculated for each producer. The data is then sorted in ascending order, and the top 5 producers are selected.The x-axis represents producers (reordered by average price) and the y-axis represents the average price per gram.
Highlighting producers with affordable products supports decisions to stock budget-friendly options, catering to price-sensitive customers.

```{r}
#Identify Producers with Cheapest Products
# Average price per producer
cheapest_producers <- df_kawa_filtered %>%
  group_by(Producent) %>%
  summarise(Average_Price = mean(Cena_za_gram, na.rm = TRUE)) %>%
  arrange(Average_Price) %>%
  head(5)

# Bar plot for producers with cheapest products
ggplot(cheapest_producers, aes(x = reorder(Producent, Average_Price), y = Average_Price)) +
  geom_bar(stat = "identity", fill = "lightcoral") +
  coord_flip() +
  labs(title = "Top 5 Producers with Cheapest Products", x = "Producer", y = "Average Price per Gram")
```

The Top 5 Producers with Cheapest Products chart reveals that COSTA COFFEE and JACOBS offer the most affordable coffee per gram, making them attractive budget options. Interestingly, some well-known brands like DALLMAYR also appear among the cheapest, indicating a broad price range within their product lines. Overall, these insights suggest that price does not directly determine quality, a few brands dominate in popularity, and affordability remains a key factor for many producers.

This visualization highlights producers with the highest average ratings. Bars represent average ratings, while overlayed points (scaled to 1/10th of total reviews) indicate the number of reviews per producer.
Combining rating and popularity data helps pinpoint producers that deliver both quality and customer satisfaction.

```{r}
# Producers with Best Reviews and most reviews
# Calculate average rating and total reviews per producer
producers_stats <- df_kawa_filtered %>%
  group_by(Producent) %>%
  summarise(
    Average_Rating = round(mean(Ocena, na.rm = TRUE), 2),  # Zaokrąglamy do 2 miejsc po przecinku
    Total_Reviews = sum(Liczba_opinii, na.rm = TRUE)
  ) %>%
  arrange(desc(Average_Rating))

# Filter for the top producers (e.g., top 10 by average rating)
top_producers_stats <- producers_stats %>%
  head(10)

# Bar plot showing both average rating and total reviews with labels
ggplot(top_producers_stats, aes(x = reorder(Producent, -Average_Rating))) +
  geom_bar(aes(y = Average_Rating), stat = "identity", fill = "gold", alpha = 0.7) +
  geom_point(aes(y = Total_Reviews), color = "blue", size = 3) + # Removed scaling
  geom_line(aes(y = Total_Reviews, group = 1), color = "blue", linetype = "dashed") +
  geom_text(aes(y = Total_Reviews, label = Average_Rating), vjust = -0.5, color = "blue", size = 4) + # Added labels for reviews
  labs(
    title = "Top Producers: Rating and Number of Reviews",
    x = "Producer",
    y = "Average Rating (Bar) / Total Reviews"
  ) +
  theme_minimal() +
  coord_flip()
```

The Top Producers: Rating and Number of Reviews chart shows a positive correlation between the number of reviews and average ratings. Well-known brands such as LAVAZZA and PELLINI have both high ratings and a large number of reviews, indicating strong customer trust and widespread market presence. Lesser-known brands tend to have fewer reviews and more varied ratings, suggesting they may not yet have established a strong reputation. 

This part of the R code calculates the correlation between various coffee attributes (e.g., bitterness, acidity, sweetness, price) using the `cor` function and visualizes the results with a heatmap. The `reshape2` library is used to melt the correlation matrix into a format suitable for plotting.
Identifying relationships between attributes helps understand which characteristics influence coffee ratings, supporting decisions about which products to prioritize.

```{r}
#Analyze Review Counts and Ratings by Flavor Characteristics
# Correlation of characteristics with reviews and ratings
characteristics_correlation <- df_kawa_filtered %>%
  select(Gorycz, Kwasowość, Słodycz, Intensywność_smaku, Ocena, Liczba_opinii) %>%
  cor(use = "complete.obs")

# Heatmap of correlation
library(reshape2)
melted_correlation <- melt(characteristics_correlation)
ggplot(melted_correlation, aes(Var1, Var2, fill = value)) +
  geom_tile() +
  scale_fill_gradient2(low = "red", mid = "white", high = "blue", midpoint = 0) +
  labs(title = "Correlation Heatmap", x = "Variable", y = "Variable")

```

The Correlation Heatmap provides insights into relationships between various factors such as ratings, price, and product attributes. Strong correlations between certain variables can help identify key drivers of customer satisfaction and pricing trends. This type of analysis is useful for understanding how different factors influence purchasing decisions, enabling better product positioning and marketing strategies.

# Summary

This report supports coffee shop assortment selection by analyzing data scraped from the Konesso website, focusing on product attributes such as flavor profiles, price, ratings, and customer reviews. The cleaned dataset provided insights into pricing patterns, sensory attributes, and producer performance, helping inform business decisions.

The analysis revealed that intensity of flavor has a stronger correlation with customer ratings, suggesting that more intense coffees tend to receive higher scores. In contrast, bitterness, sweetness, and acidity showed weaker or negligible correlations with ratings, indicating that these attributes do not significantly impact overall customer preferences.Pricing analysis indicated that while higher-priced products consistently deliver quality, midrange options often combine affordability with strong ratings, appealing to value-conscious consumers. Producer analysis highlighted those with high customer trust and top ratings as ideal candidates for partnerships, while identifying affordable producers to cater to budget-conscious segments.

The findings emphasize the importance of offering a diverse range of products spanning budget, midrange, and premium categories, enabling coffee shops to meet varied customer needs. By prioritizing products with favorable intensity levels and selecting trusted producers, businesses can optimize their offerings to attract a broad audience and strengthen their market position.

